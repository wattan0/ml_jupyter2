{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "import chainer\n",
    "from chainer import functions as F\n",
    "from chainer import initializers\n",
    "from chainer import links as L"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデル"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOLOは畳み込みニューラルネットワークを用いた高速な物体検出アルゴリズムである。  \n",
    "(YOLOにはv1, v2, v3があるが、YOLO v1の)ネットワーク全体の構造は以下のとおりである。\n",
    "\n",
    "<img src=\"image/yolo.png\", style=\"width: 600px;\">  \n",
    "(引用 「You Only Look Once: Unified, Real-Time Object Detection」)\n",
    "\n",
    "YOLOでは、画像を固定グリッド（$7 \\times 7$）に分割し、各セルごとに（2個の）バウンディングボックスの位置・大きさと信頼度、  \n",
    "そしてその中の物体クラス（20個の物体）の確率を出力する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class YOLO(chainer.Chain):\n",
    "    # YOLO v1\n",
    "    def  __init__(self):\n",
    "        super(YOLO, self).__init__()\n",
    "        # 重みの初期値\n",
    "        kwargs = {\n",
    "            'initialW': initializers.Normal(0.01),\n",
    "            'initial_bias': initializers.Zero(),\n",
    "            }\n",
    "        \n",
    "        with self.init_scope():\n",
    "            self.conv1 = L.Convolution2D(3, 64, ksize=7, stride=2, pad=3, **kwargs)\n",
    "            \n",
    "            self.conv2 = L.Convolution2D(64, 192, ksize=3, stride=1, pad=1, **kwargs)\n",
    "            \n",
    "            self.conv3_1 = L.Convolution2D(192, 128, ksize=1, stride=1, pad=0, **kwargs)\n",
    "            self.conv3_2 = L.Convolution2D(128, 256, ksize=3, stride=1, pad=1, **kwargs)\n",
    "            self.conv3_3 = L.Convolution2D(256, 256, ksize=1, stride=1, pad=0, **kwargs)\n",
    "            self.conv3_4 = L.Convolution2D(256, 512, ksize=3, stride=1, pad=1, **kwargs)\n",
    "            \n",
    "            self.conv4_1 = L.Convolution2D(512, 256, ksize=1, stride=1, pad=0, **kwargs)\n",
    "            self.conv4_2 = L.Convolution2D(256, 512, ksize=3, stride=1, pad=1, **kwargs)\n",
    "            self.conv4_3 = L.Convolution2D(512, 256, ksize=1, stride=1, pad=0, **kwargs)\n",
    "            self.conv4_4 = L.Convolution2D(256, 512, ksize=3, stride=1, pad=1, **kwargs)\n",
    "            self.conv4_5 = L.Convolution2D(512, 256, ksize=1, stride=1, pad=0, **kwargs)\n",
    "            self.conv4_6 = L.Convolution2D(256, 512, ksize=3, stride=1, pad=1, **kwargs)\n",
    "            self.conv4_7 = L.Convolution2D(512, 256, ksize=1, stride=1, pad=0, **kwargs)\n",
    "            self.conv4_8 = L.Convolution2D(256, 512, ksize=3, stride=1, pad=1, **kwargs)\n",
    "            self.conv4_9 = L.Convolution2D(512, 512, ksize=1, stride=1, pad=0, **kwargs)\n",
    "            self.conv4_10 = L.Convolution2D(512, 1024, ksize=3, stride=1, pad=1, **kwargs)\n",
    "            \n",
    "            self.conv5_1 = L.Convolution2D(1024, 512, ksize=1, stride=1, pad=0, **kwargs)\n",
    "            self.conv5_2 = L.Convolution2D(512, 1024, ksize=3, stride=1, pad=1, **kwargs)\n",
    "            self.conv5_3 = L.Convolution2D(1024, 512, ksize=1, stride=1, pad=0, **kwargs)\n",
    "            self.conv5_4 = L.Convolution2D(512, 1024, ksize=3, stride=1, pad=1, **kwargs)\n",
    "            self.conv5_5 = L.Convolution2D(1024, 1024, ksize=3, stride=1, pad=1, **kwargs)\n",
    "            self.conv5_6 = L.Convolution2D(1024, 1024, ksize=3, stride=2, pad=1, **kwargs)\n",
    "            \n",
    "            self.conv6_1 = L.Convolution2D(1024, 1024, ksize=3, stride=1, pad=1, **kwargs)\n",
    "            self.conv6_2 = L.Convolution2D(1024, 1024, ksize=3, stride=1, pad=1, **kwargs)\n",
    "                        \n",
    "            self.fc6 = L.Linear(1024 * 7 * 7, 512, **kwargs)\n",
    "            self.fc7 = L.Linear(512, 4096, **kwargs)\n",
    "            self.fc8 = L.Linear(4096, 7 * 7 * 30, **kwargs)\n",
    "            \n",
    "            \"\"\"\n",
    "            output shape: 7*7*30 = (7, 7, 30)   (7×7のグリッドそれぞれに対して30次元)\n",
    "            (7, 7, 20) : (20個の)物体クラスの確率\n",
    "            (7, 7, 2) : (2個の)バウンディングの信頼度\n",
    "            (7, 7, 2*4) : (2個の)バウンディングの位置・大きさ (4次元 x, y, w, h)\n",
    "            \"\"\"\n",
    "        \n",
    "        self.functions = self.orderd_functions()\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        h = x\n",
    "        for key, funcs in self.functions.items():\n",
    "            for func in funcs:\n",
    "                h = func(h)\n",
    "        return h\n",
    "    \n",
    "    def orderd_functions(self):\n",
    "        return collections.OrderedDict([               # size: 448\n",
    "            ('conv1',    [self.conv1, _leaky_relu]),      # size: 224\n",
    "            ('pool1',     [_max_pooling_2d]),             # size: 112\n",
    "            \n",
    "            ('conv2',    [self.conv2, _leaky_relu]),\n",
    "            ('pool2',     [_max_pooling_2d]),              # size: 56\n",
    "            \n",
    "            ('conv3_1', [self.conv3_1, _leaky_relu]),\n",
    "            ('conv3_2', [self.conv3_2, _leaky_relu]),\n",
    "            ('conv3_3', [self.conv3_3, _leaky_relu]),\n",
    "            ('conv3_4', [self.conv3_4, _leaky_relu]),\n",
    "            ('pool3',     [_max_pooling_2d]),              # size: 28\n",
    "            \n",
    "            ('conv4_1', [self.conv4_1, _leaky_relu]),\n",
    "            ('conv4_2', [self.conv4_2, _leaky_relu]),\n",
    "            ('conv4_3', [self.conv4_3, _leaky_relu]),\n",
    "            ('conv4_4', [self.conv4_4, _leaky_relu]),\n",
    "            ('conv4_5', [self.conv4_5, _leaky_relu]),\n",
    "            ('conv4_6', [self.conv4_6, _leaky_relu]),\n",
    "            ('conv4_7', [self.conv4_7, _leaky_relu]),\n",
    "            ('conv4_8', [self.conv4_8, _leaky_relu]),\n",
    "            ('conv4_9', [self.conv4_9, _leaky_relu]),\n",
    "            ('conv4_10', [self.conv4_10, _leaky_relu]),      \n",
    "            ('pool4',       [_max_pooling_2d]),            # size: 14\n",
    "            \n",
    "            ('conv5_1', [self.conv5_1, _leaky_relu]),\n",
    "            ('conv5_2', [self.conv5_2, _leaky_relu]),\n",
    "            ('conv5_3', [self.conv5_3, _leaky_relu]),\n",
    "            ('conv5_4', [self.conv5_4, _leaky_relu]),\n",
    "            ('conv5_5', [self.conv5_5, _leaky_relu]),\n",
    "            ('conv5_6', [self.conv5_6, _leaky_relu]),   # size: 7\n",
    "            \n",
    "            ('fc6',        [self.fc6, _leaky_relu]),\n",
    "            ('fc7',        [self.fc7, _leaky_relu, F.dropout]),\n",
    "            ('fc8',        [self.fc8])\n",
    "        ])\n",
    "    \n",
    "def _max_pooling_2d(x):\n",
    "    return F.max_pooling_2d(x, ksize=2)\n",
    "\n",
    "def _leaky_relu(x):\n",
    "    return F.leaky_relu(x, slope=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "yolo = YOLO()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1470)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "img = np.ones((1, 3, 448, 448), dtype=np.float32)\n",
    "output = yolo(img)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 損失関数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"image/yolo_loss.png\", style=\"width: 500px;\">  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\lambda_{\\text{coord}}$: バウンディングボックスの位置に関するロスの大きさを制御するパラメータ  \n",
    "$\\lambda_{\\text{noobj}}$: 物体の含まれていないバウンディングボックスに対するロスの大きさを制御するパラメータ  \n",
    "$S^{2}$: グリッド数  \n",
    "$B$: バウンディングボックスの数  \n",
    "$\\mathbb{1}_{ij}^{obj}$: セル$i$のバウンディングボックス$j$に物体が存在するとき$1$、存在しないとき$0$となる  \n",
    "$\\mathbb{1}_{ij}^{noobj}$: セル$i$のバウンディングボックス$j$に物体が存在しないとき$1$、存在するとき$0$となる  \n",
    "$x_{i}, y_{i}, w_{i}, h_{i}$: セル$i$における予測したバウンディングボックスの座標と幅、高さ  \n",
    "$\\hat{x}_{i}, \\hat{y}_{i}, \\hat{w}_{i}, \\hat{h}_{i}$: セル$i$における真のバウンディングボックスの位置・大きさ  \n",
    "$C_{i}$: セル$i$における予測したバウンディングボックスの信頼度  \n",
    "$\\hat{C}_{i}$: セル$i$における真のバウンディングボックスの信頼度  \n",
    "$p_{i}(c)$: セル$i$のにおける予測した物体クラス$c$の確率  \n",
    "$\\hat{p}_{i}(c)$: セル$i$のにおける真の物体クラス$c$の確率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def yolo_loss(obj, noobj, x_prob, x_conf, x_loc_xy, x_loc_wh, \n",
    "              t_prob, t_conf, t_loc_xy, t_loc_wh, lam_obj, lam_noobj):\n",
    "    # objは物体があるインデックスがTrueのarray (noobjも同様)\n",
    "    \n",
    "    loss_loc_xy = (x_loc_xy - t_loc_xy)**2\n",
    "    loss_loc_wh = (np.sqrt(x_loc_wh) - np.sqrt(t_loc_wh))**2\n",
    "    loss_loc = (obj * (loss_loc_xy + loss_loc_wh)).sum()\n",
    "    \n",
    "    loss_c_obj = (obj * (x_conf - t_conf)**2).sum()\n",
    "    loss_c_noobj = (noobj * (x_conf - t_conf)**2).sum()\n",
    "    loss_p = (obj * (x_prob - t_prob)**2).sum()\n",
    "    \n",
    "    loss = lam_obj*loss_loc + loss_c_obj + lam_noobj*loss_c_noobj + loss_p\n",
    "    return loss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
