{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SSD (Single Shot Multibox Detector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import chainer\n",
    "import chainer.functions as F\n",
    "from chainer import initializers\n",
    "import chainer.links as L"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデル"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SSDは畳み込みニューラルネットワークを用いた高速な物体検出アルゴリズムである。  \n",
    "VGG16をベースモデルとしたネットワーク構造は以下のとおりである。\n",
    "\n",
    "<img src=\"image/ssd.png\" style=\"width: 700px;\">  \n",
    "(引用 「SSD: Single Shot MultiBox Detector」)\n",
    "\n",
    "SSDの特徴はマルチスケールに対応するため複数スケールの特徴マップを利用する。  \n",
    "また、異なるアスペクト比の物体に対応するためアスペクト比ごとに識別する。\n",
    "\n",
    "出力はそれぞれのセルに対してバウンディングボックスの位置・大きさと物体クラスの確信度（softmaxを作用させて確率）である。\n",
    "\n",
    "（Non-Maximum SuppressionはSSDの出力である複数のバウンディングボックスから  \n",
    "最終的な物体検出の出力となるバウンディングボックスを絞る手法であるが詳細は省略する。）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class _Normalize(chainer.Link):\n",
    "    # conv4_3のみL2正規化後スケーリング(論文より)\n",
    "    def __init__(self, n_channels, initial=0, eps=1e-5):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "        self.add_param(\n",
    "            'scale', n_channels,\n",
    "            initializer=initializers._get_initializer(initial))\n",
    "\n",
    "    def __call__(self, x):\n",
    "        x = F.normalize(x, eps=self.eps, axis=1)\n",
    "        scale = F.broadcast_to(self.scale[:, np.newaxis, np.newaxis], x.shape)\n",
    "        return x * scale\n",
    "\n",
    "\n",
    "class SSD300(chainer.Chain):\n",
    "    # input size = 300\n",
    "    \"\"\"\n",
    "    grids = (38, 19, 10, 5, 3, 1)\n",
    "    \"\"\"\n",
    "    # 各グリッドにおけるアスペクト比\n",
    "    aspect_ratios = ((2,), (2, 3), (2, 3), (2, 3), (2,), (2,))\n",
    "    \n",
    "    # 畳み込み層の重みの初期値\n",
    "    conv_init = {\n",
    "        'initialW': initializers.GlorotUniform(),\n",
    "        'initial_bias': initializers.Zero(),\n",
    "    }\n",
    "    # スケーリング定数\n",
    "    norm_init = {\n",
    "        'initial': initializers.Constant(20),\n",
    "    }\n",
    "\n",
    "    def __init__(self, n_classes):\n",
    "        self.n_classes = n_classes\n",
    "\n",
    "        super(SSD300, self).__init__()\n",
    "        with self.init_scope():\n",
    "            # VGG16と同じ\n",
    "            self.conv1_1 = L.Convolution2D(3, 64, ksize=3, stride=1, pad=1, **self.conv_init)\n",
    "            self.conv1_2 = L.Convolution2D(64, 64, ksize=3, stride=1, pad=1, **self.conv_init)\n",
    "\n",
    "            self.conv2_1 = L.Convolution2D(64, 128, ksize=3, stride=1, pad=1, **self.conv_init)\n",
    "            self.conv2_2 = L.Convolution2D(128, 128, ksize=3, stride=1, pad=1, **self.conv_init)\n",
    "\n",
    "            self.conv3_1 = L.Convolution2D(128, 256, ksize=3, stride=1, pad=1, **self.conv_init)\n",
    "            self.conv3_2 = L.Convolution2D(256, 256, ksize=3, stride=1, pad=1, **self.conv_init)\n",
    "            self.conv3_3 = L.Convolution2D(256, 256, ksize=3, stride=1, pad=1, **self.conv_init)\n",
    "\n",
    "            self.conv4_1 = L.Convolution2D(256, 512, ksize=3, stride=1, pad=1, **self.conv_init)\n",
    "            self.conv4_2 = L.Convolution2D(512, 512, ksize=3, stride=1, pad=1, **self.conv_init)\n",
    "            self.conv4_3 = L.Convolution2D(512, 512, ksize=3, stride=1, pad=1, **self.conv_init)\n",
    "            self.norm4 = _Normalize(512, **self.norm_init)\n",
    "\n",
    "            self.conv5_1 = L.Convolution2D(512, 512, ksize=3, stride=1, pad=1, **self.conv_init)\n",
    "            self.conv5_2 = L.Convolution2D(512, 512, ksize=3, stride=1, pad=1, **self.conv_init)\n",
    "            self.conv5_3 = L.Convolution2D(512, 512, ksize=3, stride=1, pad=1, **self.conv_init)\n",
    "            \n",
    "            # 追加の畳み込み層\n",
    "            self.conv6 = L.DilatedConvolution2D(\n",
    "                                512, 1024, ksize=3, stride=1, pad=6, dilate=6, **self.conv_init)  # 間隔を開けた畳み込み層\n",
    "            self.conv7 = L.Convolution2D(1024, 1024, ksize=1, stride=1, pad=0, **self.conv_init)\n",
    "\n",
    "            self.conv8_1 = L.Convolution2D(1024, 256, ksize=1, stride=1, pad=0, **self.conv_init)\n",
    "            self.conv8_2 = L.Convolution2D(256, 512, ksize=3, stride=2, pad=1, **self.conv_init)\n",
    "\n",
    "            self.conv9_1 = L.Convolution2D(512, 128, ksize=1, stride=1, pad=0, **self.conv_init)\n",
    "            self.conv9_2 = L.Convolution2D(128, 256, ksize=3, stride=2, pad=1, **self.conv_init)\n",
    "\n",
    "            self.conv10_1 = L.Convolution2D(256, 128, ksize=1, stride=1, pad=0, **self.conv_init)\n",
    "            self.conv10_2 = L.Convolution2D(128, 256, ksize=3, stride=1, pad=0, **self.conv_init)\n",
    "\n",
    "            self.conv11_1 = L.Convolution2D(256, 128, ksize=1, stride=1, pad=0, **self.conv_init)\n",
    "            self.conv11_2 = L.Convolution2D(128, 256, ksize=3, stride=1, pad=0, **self.conv_init)\n",
    "            \n",
    "            # バウンディングボックスの位置用\n",
    "            self.loc = chainer.ChainList()  # (空のchainListインスタンス)\n",
    "            # 物体クラスの確信度用\n",
    "            self.conf = chainer.ChainList()\n",
    "\n",
    "        for ar in self.aspect_ratios:\n",
    "            # バウンディングボックスの数\n",
    "            n = (len(ar) + 1) * 2\n",
    "            # chainListインスタンスにlinkを追加\n",
    "            # ボックスの位置・大きさ(x, y, w, h)\n",
    "            self.loc.add_link(L.Convolution2D(\n",
    "                None, n * 4, ksize=3, stride=1, pad=1, **self.conv_init))\n",
    "            # 物体クラスの確信度(c1, c2, ..., cm, cm+1) (背景の確信度も)\n",
    "            self.conf.add_link(L.Convolution2D(\n",
    "                None, n * (self.n_classes + 1), ksize=3, stride=1, pad=1, **self.conv_init))\n",
    "\n",
    "    def _features(self, x):\n",
    "        ys = []\n",
    "        # size: 300\n",
    "        h = F.relu(self.conv1_1(x))\n",
    "        h = F.relu(self.conv1_2(h))\n",
    "        h = F.max_pooling_2d(h, ksize=2)\n",
    "        # size: 150\n",
    "        h = F.relu(self.conv2_1(h))\n",
    "        h = F.relu(self.conv2_2(h))\n",
    "        h = F.max_pooling_2d(h, ksize=2)\n",
    "        # size: 75\n",
    "        h = F.relu(self.conv3_1(h))\n",
    "        h = F.relu(self.conv3_2(h))\n",
    "        h = F.relu(self.conv3_3(h))\n",
    "        h = F.max_pooling_2d(h, ksize=2)\n",
    "        # size: 38\n",
    "        h = F.relu(self.conv4_1(h))\n",
    "        h = F.relu(self.conv4_2(h))\n",
    "        h = F.relu(self.conv4_3(h))\n",
    "        ys.append(self.norm4(h))\n",
    "        h = F.max_pooling_2d(h, ksize=2)\n",
    "        # size: 19\n",
    "        h = F.relu(self.conv5_1(h))\n",
    "        h = F.relu(self.conv5_2(h))\n",
    "        h = F.relu(self.conv5_3(h))\n",
    "        h = F.max_pooling_2d(h, ksize=3, stride=1, pad=1)\n",
    "        # size: 19\n",
    "        h = F.relu(self.conv6(h))\n",
    "        h = F.relu(self.conv7(h))\n",
    "        # size: 19\n",
    "        ys.append(h)\n",
    "\n",
    "        for i in range(8, 11 + 1):\n",
    "            h = F.relu(self['conv{:d}_1'.format(i)](h))\n",
    "            h = F.relu(self['conv{:d}_2'.format(i)](h))\n",
    "            ys.append(h)\n",
    "        # conv8_2 size: 9\n",
    "        # conv9_2 size: 5\n",
    "        # conv10_2 size: 3\n",
    "        # conv11_2 size: 1\n",
    "\n",
    "        return ys\n",
    "\n",
    "    def _multibox(self, xs):\n",
    "        \"\"\"\n",
    "        バウンディングボックスの総数\n",
    "        n = (4, 6, 6, 6, 4, 4)\n",
    "        h*w = (38, 19, 10, 5, 3, 1)^2\n",
    "        h*w*n = 4*38^2 + ... + 4*1^2 = 8732\n",
    "        \"\"\"\n",
    "        ys_loc = []\n",
    "        ys_conf = []\n",
    "        for i, x in enumerate(xs):\n",
    "            loc = self.loc[i](x)   # (batch_size, n*4, h, w)\n",
    "            loc = F.transpose(loc, (0, 2, 3, 1))  # (batch_size, h, w, *n4)\n",
    "            loc = F.reshape(loc, (loc.shape[0], -1, 4))  # (batch_size, h*w*n, 4)\n",
    "            ys_loc.append(loc)\n",
    "\n",
    "            conf = self.conf[i](x)  # (batch_size, n*(n_classes+1), h, w)\n",
    "            conf = F.transpose(conf, (0, 2, 3, 1))  # (batch_size, h, w, n*(n_classes+1))\n",
    "            conf = F.reshape(\n",
    "                conf, (conf.shape[0], -1, self.n_classes + 1))  # # (batch_size, h*w*n, n_classes+1)\n",
    "            ys_conf.append(conf)\n",
    "\n",
    "        y_loc = F.concat(ys_loc, axis=1)\n",
    "        y_conf = F.concat(ys_conf, axis=1)\n",
    "\n",
    "        return y_loc, y_conf\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return self._multibox(self._features(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ssd = SSD300(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 8732, 4) (1, 8732, 11)\n"
     ]
    }
   ],
   "source": [
    "img = np.ones((1, 3, 300, 300), dtype=np.float32)\n",
    "output = ssd(img)\n",
    "print(output[0].shape, output[1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 損失関数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"image/ssd_loss.png\" style=\"width: 600px;\">  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$N$: マッチしたバウンディングボックスの数  \n",
    "$L_{conf}$: 物体クラスの確信度に対するロス  \n",
    "$L_{loc}$: バウンディングボックスの位置・大きさに対するロス  \n",
    "$\\alpha$: 物体クラスの確信度に対するロスとバウンディングボックスの位置・大きさに対するロスの割合を制御するパラメータ  \n",
    "$Pos, Neg$: ポジティブサンプル（物体が含まれる）、ネガティブサンプル（物体が含まれない）  \n",
    "$cx, cy, w, h$: バウンディングボックスの中心座標と幅、高さ  \n",
    "$x_{ij}^{p}$: バウンディングボックス$i$、カテゴリ$p$、真のボックス$j$であれば$1$、そうでないなら$0$  \n",
    "$smooth_{L1}$: smooth L1誤差  \n",
    "$l_{i}^{m}(d_{i}^{m})$: 予測したバウンディングボックス$i$の位置（中心座標と幅、高さ）  \n",
    "$g_{i}^{m}$: 真のバウンディングボックス$j$の位置（中心座標と幅、高さ）  \n",
    "$c_{i}^{p}$: バウンディングボックス$i$におけるカテゴリ$p$の確信度（$p=0$は背景）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _elementwise_softmax_cross_entropy(x, t):\n",
    "    # -log(cp_hat) = -cp + logsumexp(cp)\n",
    "    p = F.reshape(\n",
    "        F.select_item(F.reshape(x, (-1, x.shape[-1])), F.flatten(t)),\n",
    "        t.shape)\n",
    "    return F.logsumexp(x, axis=-1) - p\n",
    "\n",
    "\n",
    "def _mine_hard_negative(loss, pos, k):\n",
    "    # ハードネガティブがTrueになるarray（!pos == hard_negではない）\n",
    "    # negの中でcp_hatが小さいpがhart_neg（kはハードネガティブの個数）\n",
    "    rank = (loss * (pos - 1)).argsort(axis=1).argsort(axis=1)\n",
    "    hard_neg = rank < (pos.sum(axis=1) * k)[:, np.newaxis]\n",
    "    return hard_neg\n",
    "\n",
    "\n",
    "def multibox_loss(x_loc, x_conf, t_loc, t_conf, k):\n",
    "    # ポジティブ（物体が含まれる）\n",
    "    pos = t_conf.data > 0\n",
    "    # N=0ならloss=0\n",
    "    if np.logical_not(pos).all():\n",
    "        return 0, 0\n",
    "\n",
    "    x_loc = F.reshape(x_loc, (-1, 4))\n",
    "    t_loc = F.reshape(t_loc, (-1, 4))\n",
    "    # smooth l1 loss  = huber_loss(a=1)\n",
    "    # (ssdの出力はcx, cy, log(w), log(h))\n",
    "    loss_loc = F.huber_loss(x_loc, t_loc, 1)\n",
    "    loss_loc *= pos.flatten().astype(loss_loc.dtype)\n",
    "    loss_loc = F.sum(loss_loc) / pos.sum()\n",
    "\n",
    "    loss_conf = _elementwise_softmax_cross_entropy(x_conf, t_conf)\n",
    "    hard_neg = _mine_hard_negative(loss_conf.data, pos, k)\n",
    "    loss_conf *= xp.logical_or(pos, hard_neg).astype(loss_conf.dtype)\n",
    "    loss_conf = F.sum(loss_conf) / pos.sum()\n",
    "\n",
    "    return loss_loc, loss_conf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
